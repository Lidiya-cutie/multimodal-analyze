## Описание проекта: Оптимизированный пайплайн обработки изображений с мультимодальным анализом

### 1. Общее назначение
Проект представляет собой высокооптимизированный пайплайн для обработки изображений с:
- Извлечением текстового описания
- Генерацией векторных представлений
- Категоризацией контента
- Ключевыми словами
- Анализом текста на изображениях

### 2. Ключевые особенности
- **Гибкая архитектура**: Поддержка нескольких моделей (Qwen2-VL, CLIP, SentenceTransformer, FastText, Llama 3.1)
- **Оптимизация ресурсов**: 
  - Кэширование моделей (LRU cache)
  - Управление памятью GPU
  - Пакетная обработка
- **Отказоустойчивость**: Механизмы восстановления после сбоев
- **Мониторинг**: Подробное логирование всех этапов

### 3. Технические детали

#### Модели и технологии:
1. **Qwen2-VL-7B-Instruct** - мультимодальная модель для анализа изображений
2. **SentenceTransformer** - для генерации текстовых эмбеддингов
3. **CLIP** - для генерации визуальных эмбеддингов
4. **FastText** - альтернативный метод векторизации текста
5. **Llama 3.1 8B** - для улучшенного извлечения и структурирования текста

#### Параметры конфигурации:
```python
MODEL_CACHE_SIZE = 3            # Кол-во моделей в кэше LRU
MEMORY_CLEAR_THRESHOLD = 2      # Порог очистки памяти (GB)
IMAGE_MAX_SIZE = 384            # Макс. размер изображения
BATCH_PROCESS_SIZE = 1          # Размер батча
```

### 4. Рабочий процесс

#### Этапы обработки:
1. **Подготовка изображения**:
   - Конвертация в RGB
   - Ресайз с сохранением пропорций
   - Нормализация

2. **Мультимодальный анализ**:
   - Генерация текстового описания (Qwen2-VL)
   - Векторизация текста (SentenceTransformer + FastText)
   - Векторизация изображения (CLIP)

3. **Улучшение текста** (Llama 3.1):
   - Структурирование в JSON
   - Извлечение:
     - Основного описания
     - Категории
     - Ключевых слов
     - Текста с изображения

4. **Сохранение результатов**:
   - Инкрементальное добавление в CSV
   - Пропуск уже обработанных файлов

### 5. Особенности реализации

#### Оптимизации:
- **Кэширование моделей**: `@lru_cache(maxsize=MODEL_CACHE_SIZE)`
- **Управление памятью GPU**:
  ```python
  os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
  adaptive_memory_management()
  ```
- **Пакетная обработка**: Постепенная запись результатов (каждые 10 изображений)

#### Обработка ошибок:
- Подробное логирование всех этапов
- Механизм восстановления после OOM
- Сохранение состояния при прерывании

### 6. Формат выходных данных

Пример структуры CSV:
```csv
image_path,text,description,categories,keywords,image_text,text_vector,word2vec_vector,image_vector,timestamp,error,llama_extracted
/path/to/image.jpg,"Полное описание...","Краткое описание...","Категория","ключ1, ключ2","Текст на изображении",[...],[...],[...],"2025-05-13T06:12:38",null,{json}
```

### 7. Рекомендации по развертыванию

#### Требования:
- GPU с ≥16GB памяти (для Qwen2-VL 7B)
- Python 3.8+
- Основные зависимости:
  - PyTorch с CUDA
  - Transformers
  - SentenceTransformers
  - Gensim
  - llama-cpp-python

#### Запуск:
```bash
python /path/to/vec_qwen.py
```

#### Перезапуск после прерывания:
Автоматически продолжит с последнего обработанного изображения благодаря:
```python
processed = set(pd.read_csv(output_file, usecols=["image_path"])["image_path"].values)
image_paths = [p for p in image_paths if p not in processed]
```

### 8. Производительность

На основе лога:
- Среднее время обработки 1 изображения: ~30 сек
- Обработка всего датасета (24,415 изображений): ~203 часа
- Использование памяти:
  - GPU: динамически управляется
  - CPU: ~3GB для Llama 3.1

### 9. Дальнейшее развитие

Возможные улучшения:
1. Параллельная обработка изображений
2. Оптимизация запросов к Llama
3. Добавление механизма приоритезации
4. Интеграция с облачными хранилищами

